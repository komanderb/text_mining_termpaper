{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d68e44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "import nltk                                                             # Natural language Toolkit\n",
    "from nltk.stem import SnowballStemmer                                   # Porter's II Stemmer\n",
    "from nltk import word_tokenize                                          # Document tokenizer\n",
    "from nltk.corpus import stopwords  \n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f773c919",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/fairy_tales_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73c544ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "remove_pronouns=['he',\n",
    " 'him',\n",
    " 'his',\n",
    " 'himself',\n",
    " 'she',\n",
    " \"she's\",\n",
    " 'her',\n",
    " 'hers',\n",
    " 'herself']\n",
    "stopwords = [word for word in remove_pronouns if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "703ec924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "import re\n",
    "#1) Preprocess\n",
    "### Cleaning Function \n",
    "def cleaning(text):\n",
    "    # Remove Punctuation \n",
    "    clean_text=text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove Symbols \n",
    "    clean_text=re.sub(r'[^\\w]', ' ', clean_text)\n",
    "    # Remove Numbers\n",
    "    #clean_text=clean_text.translate(str.maketrans('', '', string.digits))\n",
    "    # Put in Lowercase \n",
    "    #clean_text=clean_text.lower()\n",
    "    # Remove StopWords\n",
    "    var=clean_text.split()\n",
    "    filtered_list=[]\n",
    "    for word in var:\n",
    "        if word not in stopwords:\n",
    "            filtered_list.append(word)\n",
    "    clean_text=\" \".join(map(str, filtered_list))\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "#def stemming(text):\n",
    " #   stemming_output = ' '.join([englishStemmer.stem(w) for w in text.split()])\n",
    "  #return stemming_output \n",
    "\n",
    "#load stopwords\n",
    "df['clean_text']=[cleaning(i) for i in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97b73924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That night the warriors from the land of the Goths were feasted in the'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'][200000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d15f1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         THE HEROES OR GREEK FAIRY TALES FOR MY CHILDRE...\n",
       "1         THE HEROES OR GREEK FAIRY TALES FOR MY CHILDRE...\n",
       "2         THE HEROES OR GREEK FAIRY TALES FOR MY CHILDRE...\n",
       "3         THE HEROES OR GREEK FAIRY TALES FOR MY CHILDRE...\n",
       "4         THE HEROES OR GREEK FAIRY TALES FOR MY CHILDRE...\n",
       "                                ...                        \n",
       "242821    SLAV TALES Illustration Illustration From The ...\n",
       "242822    SLAV TALES Illustration Illustration From The ...\n",
       "242823    SLAV TALES Illustration Illustration From The ...\n",
       "242824    SLAV TALES Illustration Illustration From The ...\n",
       "242825    SLAV TALES Illustration Illustration From The ...\n",
       "Name: book_raw_text, Length: 242826, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"book_raw_text\"]=df.groupby(['gutenberg_id'])['clean_text'].transform(lambda x: ' '.join(x))\n",
    "df['book_raw_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2d4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20232\\1507606882.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_tokenized\"][i]=list(filter(None, df[\"text_tokenized\"][i]))\n",
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_20232\\1507606882.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_tokenized\"][i]=[x.lower() for x in df[\"text_tokenized\"][i]]\n"
     ]
    }
   ],
   "source": [
    "df.drop_duplicates(subset = ['gutenberg_id'],inplace = True)\n",
    "df.reset_index(inplace = True)\n",
    "df[\"book_text2\"]=[re.sub(r'[A-Z]+(?![a-z])', '', x) for x in df[\"book_raw_text\"]]\n",
    "def tokenization(text):\n",
    "    tokens = re.split(' ',text)\n",
    "    return tokens\n",
    "\n",
    "df['text_tokenized']= df['book_text2'].apply(lambda x: tokenization(x))\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df[\"text_tokenized\"][i]=list(filter(None, df[\"text_tokenized\"][i]))\n",
    "    df[\"text_tokenized\"][i]=[x.lower() for x in df[\"text_tokenized\"][i]]\n",
    "    \n",
    "## lemmatize\n",
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(s):\n",
    "\n",
    "    s = [wnl.lemmatize(word) for word in s]\n",
    "    return s\n",
    "\n",
    "df = df.assign(text_lemma = df.text_tokenized.apply(lambda x: lemmatize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b163aa0d",
   "metadata": {},
   "source": [
    "### Playing around with Word2Vec\n",
    "\n",
    "Just training a simple Word2Vec model on the given data. \n",
    "Given the minimal preprocessing and the small size of training data,\n",
    "this is just for visualisation purposes.\n",
    "\n",
    "1. Use pretrained Word2Vec (differences?)\n",
    "2. Train on larger corpus (data is loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d83eeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('witch', 0.8128074407577515),\n",
       " ('farmer', 0.812404453754425),\n",
       " ('boy', 0.7983742952346802),\n",
       " ('girl', 0.7864857316017151),\n",
       " ('princess', 0.7820737957954407),\n",
       " ('husband', 0.7642733454704285),\n",
       " ('man', 0.7634108066558838),\n",
       " ('lad', 0.7586875557899475),\n",
       " ('prince', 0.7575526237487793),\n",
       " ('fox', 0.7559700012207031),\n",
       " ('lady', 0.7437622547149658),\n",
       " ('herself', 0.7404909729957581),\n",
       " ('bear', 0.738444447517395),\n",
       " ('ogre', 0.7384242415428162),\n",
       " ('angry', 0.7374202013015747),\n",
       " ('shedragon', 0.736622154712677),\n",
       " ('quail', 0.7299108505249023),\n",
       " ('sparrow', 0.7228524088859558),\n",
       " ('tiger', 0.7227628827095032),\n",
       " ('priest', 0.7213254570960999),\n",
       " ('widow', 0.71696537733078),\n",
       " ('duckling', 0.7157494425773621),\n",
       " ('nurse', 0.7153459787368774),\n",
       " ('poor', 0.7146952748298645),\n",
       " ('loki', 0.7144445776939392),\n",
       " ('voice', 0.7085778117179871),\n",
       " ('magician', 0.7072442173957825),\n",
       " ('maiden', 0.7040152549743652),\n",
       " ('rabbit', 0.7038483619689941),\n",
       " ('mother', 0.7016187906265259)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "female = gensim.models.Word2Vec(df['text_lemma'], min_count=10, vector_size=100)\n",
    "female.wv.most_similar(positive=['she', 'woman'], topn=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96120bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chattering', 0.41853976249694824),\n",
       " ('little', 0.41317519545555115),\n",
       " ('two', 0.41122376918792725),\n",
       " ('nouronnihar', 0.39704108238220215),\n",
       " ('accompanying', 0.38285401463508606),\n",
       " ('together', 0.3704138398170471),\n",
       " ('told', 0.36129969358444214),\n",
       " ('wooed', 0.3611011505126953),\n",
       " ('retainer', 0.3553624749183655),\n",
       " ('entertained', 0.35201704502105713),\n",
       " ('halfdan', 0.3470708429813385),\n",
       " ('bridled', 0.34634095430374146),\n",
       " ('men', 0.34315475821495056),\n",
       " ('kitchenmaid', 0.34312212467193604),\n",
       " ('quarreling', 0.3395988345146179),\n",
       " ('betrothed', 0.3393055200576782),\n",
       " ('frail', 0.33500659465789795),\n",
       " ('destroys', 0.33394140005111694),\n",
       " ('papoose', 0.3339385986328125),\n",
       " ('tang', 0.3303912580013275),\n",
       " ('helper', 0.32840102910995483),\n",
       " ('lured', 0.3273230791091919),\n",
       " ('moore', 0.324090838432312),\n",
       " ('ivy', 0.32304617762565613),\n",
       " ('called', 0.32278624176979065),\n",
       " ('charmed', 0.32214006781578064),\n",
       " ('gudarz', 0.317789763212204),\n",
       " ('wearily', 0.3135395348072052),\n",
       " ('greyhound', 0.31257039308547974),\n",
       " ('weeping', 0.31234124302864075)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.wv.most_similar(positive=['woman'], negative = ['man'], topn = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "895333da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('desirable', 0.3882335126399994),\n",
       " ('gad', 0.3858051896095276),\n",
       " ('pronounce', 0.37855178117752075),\n",
       " ('he', 0.35565584897994995),\n",
       " ('undertook', 0.33176374435424805),\n",
       " ('hint', 0.32833826541900635),\n",
       " ('any', 0.3263907730579376),\n",
       " ('himself', 0.3229527175426483),\n",
       " ('confirm', 0.3220430314540863),\n",
       " ('rt', 0.31863224506378174),\n",
       " ('drake', 0.3108677566051483),\n",
       " ('something', 0.3044278621673584),\n",
       " ('prized', 0.3036625385284424),\n",
       " ('furnace', 0.3019540309906006),\n",
       " ('handsomer', 0.30030983686447144),\n",
       " ('anything', 0.298856645822525),\n",
       " ('mourn', 0.28809794783592224),\n",
       " ('laddie', 0.28802409768104553),\n",
       " ('gilbert', 0.28658607602119446),\n",
       " ('sooner', 0.2828972637653351),\n",
       " ('crusade', 0.2780119478702545),\n",
       " ('communicated', 0.27569907903671265),\n",
       " ('modestly', 0.2755510210990906),\n",
       " ('succeeds', 0.2750774621963501),\n",
       " ('purr', 0.2739391624927521),\n",
       " ('this', 0.27375197410583496),\n",
       " ('it', 0.2693142294883728),\n",
       " ('gilliflower', 0.26882362365722656),\n",
       " ('puppet', 0.26813894510269165),\n",
       " ('better', 0.26772525906562805)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.wv.most_similar(positive=['man'], negative = ['woman'], topn = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15667fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('her', 0.5400070548057556),\n",
       " ('whuppie', 0.35095661878585815),\n",
       " ('bragi', 0.34265321493148804),\n",
       " ('herself', 0.33557069301605225),\n",
       " ('serendib', 0.3293025493621826),\n",
       " ('wearily', 0.3260687589645386),\n",
       " ('319', 0.31283852458000183),\n",
       " ('husband', 0.31151673197746277),\n",
       " ('bribed', 0.30957385897636414),\n",
       " ('hreidmar', 0.2970789074897766),\n",
       " ('moore', 0.2935079336166382),\n",
       " ('ruth', 0.28512439131736755),\n",
       " ('little', 0.2747052311897278),\n",
       " ('spindle', 0.2696342170238495),\n",
       " ('un', 0.26040130853652954),\n",
       " ('clung', 0.2563196122646332),\n",
       " ('macintyre', 0.2553767263889313),\n",
       " ('fancying', 0.25477054715156555),\n",
       " ('alcinous', 0.2487962543964386),\n",
       " ('talus', 0.2468264102935791),\n",
       " ('beautiful', 0.2432371824979782),\n",
       " ('girl', 0.24278651177883148),\n",
       " ('kent', 0.24163919687271118),\n",
       " ('hullo', 0.2404334396123886),\n",
       " ('hair', 0.23962914943695068),\n",
       " ('wunzh', 0.23682096600532532),\n",
       " ('forbear', 0.23535561561584473),\n",
       " ('stepdaughter', 0.23452749848365784),\n",
       " ('upped', 0.23434209823608398),\n",
       " ('vegtam', 0.23079629242420197)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female.wv.most_similar(positive=['she'], negative = ['he'], topn = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4875398d",
   "metadata": {},
   "source": [
    "If we want to choose a pretrained model, see below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3318837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader\n",
    "# Show all available models in gensim-data\n",
    "print(list(gensim.downloader.info()['models'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631288ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "\n",
    "# model_name = gensim.downloader.load('model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa73350",
   "metadata": {},
   "source": [
    "### WEAT association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6dc3db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vector(word_list, model):\n",
    "    vector = []\n",
    "    for i in word_list: \n",
    "        vector.append(model.wv[i])\n",
    "    return vector\n",
    "\n",
    "## all other functions from: https://github.com/chadaeun/weat_replication/blob/master/lib/weat.py\n",
    "\n",
    "def unit_vector(vec):\n",
    "    \"\"\"\n",
    "    Returns unit vector\n",
    "    \"\"\"\n",
    "    return vec / np.linalg.norm(vec)\n",
    "\n",
    "\n",
    "def cos_sim(v1, v2):\n",
    "    \"\"\"\n",
    "    Returns cosine of the angle between two vectors\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.clip(np.tensordot(v1_u, v2_u, axes=(-1, -1)), -1.0, 1.0)\n",
    "\n",
    "\n",
    "def weat_association(W, A, B):\n",
    "    \"\"\"\n",
    "    Returns association of the word w in W with the attribute for WEAT score.\n",
    "    s(w, A, B)\n",
    "    :param W: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: (len(W), ) shaped numpy ndarray. each rows represent association of the word w in W\n",
    "    \"\"\"\n",
    "    return np.mean(cos_sim(W, A), axis=-1) - np.mean(cos_sim(W, B), axis=-1)\n",
    "\n",
    "\n",
    "def weat_score(X, Y, A, B):\n",
    "    \"\"\"\n",
    "    Returns WEAT score\n",
    "    X, Y, A, B must be (len(words), dim) shaped numpy ndarray\n",
    "    CAUTION: this function assumes that there's no intersection word between X and Y\n",
    "    :param X: target words' vector representations\n",
    "    :param Y: target words' vector representations\n",
    "    :param A: attribute words' vector representations\n",
    "    :param B: attribute words' vector representations\n",
    "    :return: WEAT score\n",
    "    \"\"\"\n",
    "\n",
    "    x_association = weat_association(X, A, B)\n",
    "    y_association = weat_association(Y, A, B)\n",
    "\n",
    "\n",
    "    tmp1 = np.mean(x_association, axis=-1) - np.mean(y_association, axis=-1)\n",
    "    tmp2 = np.std(np.concatenate((x_association, y_association), axis=0))\n",
    "\n",
    "    return tmp1 / tmp2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecd9b31",
   "metadata": {},
   "source": [
    "A simple implementation, based on [basic domains/attribute words](https://github.com/chadaeun/weat_replication/tree/master/weat)\n",
    "This is just a placeholder until we find better domains/target words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c053631d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('husband', 0.9320796132087708), ('sparrow', 0.9143039584159851), ('farmer', 0.9057610630989075), ('bride', 0.9019930362701416), ('priest', 0.8953858613967896), ('boy', 0.8903483152389526), ('lady', 0.8899587988853455), ('lad', 0.889054000377655), ('nurse', 0.874434769153595), ('horn', 0.8740369081497192), ('granny', 0.8735975027084351), ('servant', 0.8701795339584351), ('magician', 0.8678514361381531), ('weep', 0.8665828108787537), ('maiden', 0.8610840439796448)]\n",
      "[('farmer', 0.918499767780304), ('princess', 0.9104329943656921), ('wife', 0.9100356101989746), ('priest', 0.9009794592857361), ('servant', 0.8931905627250671), ('horn', 0.8931836485862732), ('emperor', 0.8854930996894836), ('lad', 0.8845152854919434), ('sparrow', 0.8836773037910461), ('bride', 0.882102370262146), ('magician', 0.8811991810798645), ('message', 0.8771030306816101), ('mother', 0.8769028186798096), ('ogre', 0.8744143843650818), ('master', 0.8676860928535461)]\n"
     ]
    }
   ],
   "source": [
    "female_words = ['woman', 'she', 'her', 'herself', 'girl', 'sister', 'daughter', 'mother', 'hers', 'female', 'queen', 'princess', 'wife']\n",
    "male_words = ['man', 'he', 'him', 'himself', 'boy', 'brother', 'son', 'father', 'his', 'male', 'king', 'prince', 'husband']\n",
    "print(female.wv.most_similar(positive=female_words, topn = 15))\n",
    "print(female.wv.most_similar(positive= male_words, topn = 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9c21070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pleasant_words = ['caress', 'freedom', 'health', 'love', 'peace', 'cheer', 'friend', 'heaven', 'loyal', 'pleasure',\n",
    "                   'diamond', 'gentle', 'honest', 'lucky', 'rainbow', 'diploma', 'gift', 'honor', 'miracle', 'sunrise', 'family',\n",
    "                   'happy', 'laughter', 'paradise', 'vacation']\n",
    "\n",
    "unpleasant_words = ['abuse', 'crash', 'filth', 'murder', 'sickness', 'accident', 'death', 'grief', 'poison', 'stink',\n",
    "                    'assault', 'disaster', 'hatred', 'pollute', 'tragedy', 'divorce', 'jail', 'poverty', 'ugly', 'cancer',\n",
    "                    'kill', 'rotten', 'vomit', 'agony', 'prison']\n",
    "\n",
    "\n",
    "def get_word_vectors(words, model):\n",
    "        \"\"\"\n",
    "        Returns word vectors represent words\n",
    "        :param words: iterable of words\n",
    "        :return: (len(words), dim) shaped numpy ndarrary which is word vectors\n",
    "        \"\"\"\n",
    "        words = [w for w in words if w in model.wv.key_to_index]\n",
    "        return model.wv[words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9fb4877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, A, B = [get_word_vectors(i, female) for i in [female_words, male_words, pleasant_words, unpleasant_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "996d4574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3483745"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcb752d",
   "metadata": {},
   "source": [
    "That's a bit surprising but the interpretation is goes analogous to [that](https://developers.googleblog.com/2018/04/text-embedding-models-contain-bias.html): \n",
    "> For example, the target lists for the first WEAT test are types of flowers and insects, and the attributes are pleasant words (e.g., \"love\", \"peace\") and unpleasant words (e.g., \"hatred,\" \"ugly\"). The overall test score is the degree to which flowers are more associated with the pleasant words, relative to insects. A high positive score (the score can range between 2.0 and -2.0) means that flowers are more associated with pleasant words, and a high negative score means that insects are more associated with pleasant words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "af96daee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting responsibly\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)'))': /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)'))': /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)'))': /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)'))': /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)'))': /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl\n",
      "ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/44/64/72211de680c21fe6cea67da182db965861603d311c67839ab39cc7226780/responsibly-0.1.2-py3-none-any.whl (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1129)')))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install responsibly\n",
    "\n",
    "# if anyone is able to pip install that \n",
    "# my pip is fucked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
